{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yunyawang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from table_bert import TableBertModel\n",
    "from table_bert import Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['phase', 'table_id', 'question', 'sql', 'answer', 'sql_query'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>table_id</th>\n",
       "      <th>question</th>\n",
       "      <th>sql</th>\n",
       "      <th>answer</th>\n",
       "      <th>sql_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1-10015132-16</td>\n",
       "      <td>What is terrence ross' nationality</td>\n",
       "      <td>{'sel': 2, 'conds': [[0, 0, 'Terrence Ross']],...</td>\n",
       "      <td>[united states]</td>\n",
       "      <td>{'agg_index': 0, 'cond_ops': ['=', '&gt;', '&lt;', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1-10015132-16</td>\n",
       "      <td>What clu was in toronto 1995-96</td>\n",
       "      <td>{'sel': 5, 'conds': [[4, 0, '1995-96']], 'agg'...</td>\n",
       "      <td>[arkansas]</td>\n",
       "      <td>{'agg_index': 0, 'cond_ops': ['=', '&gt;', '&lt;', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1-10015132-16</td>\n",
       "      <td>which club was in toronto 2003-06</td>\n",
       "      <td>{'sel': 5, 'conds': [[4, 0, '2003-06']], 'agg'...</td>\n",
       "      <td>[michigan]</td>\n",
       "      <td>{'agg_index': 0, 'cond_ops': ['=', '&gt;', '&lt;', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1-10015132-16</td>\n",
       "      <td>how many schools or teams had jalen rose</td>\n",
       "      <td>{'sel': 5, 'conds': [[0, 0, 'Jalen Rose']], 'a...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'agg_index': 3, 'cond_ops': ['=', '&gt;', '&lt;', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1-10083598-1</td>\n",
       "      <td>Where was Assen held?</td>\n",
       "      <td>{'sel': 2, 'conds': [[3, 0, 'Assen']], 'agg': 0}</td>\n",
       "      <td>[netherlands]</td>\n",
       "      <td>{'agg_index': 0, 'cond_ops': ['=', '&gt;', '&lt;', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phase       table_id                                  question  \\\n",
       "0      1  1-10015132-16        What is terrence ross' nationality   \n",
       "1      1  1-10015132-16           What clu was in toronto 1995-96   \n",
       "2      1  1-10015132-16         which club was in toronto 2003-06   \n",
       "3      1  1-10015132-16  how many schools or teams had jalen rose   \n",
       "4      1   1-10083598-1                     Where was Assen held?   \n",
       "\n",
       "                                                 sql           answer  \\\n",
       "0  {'sel': 2, 'conds': [[0, 0, 'Terrence Ross']],...  [united states]   \n",
       "1  {'sel': 5, 'conds': [[4, 0, '1995-96']], 'agg'...       [arkansas]   \n",
       "2  {'sel': 5, 'conds': [[4, 0, '2003-06']], 'agg'...       [michigan]   \n",
       "3  {'sel': 5, 'conds': [[0, 0, 'Jalen Rose']], 'a...              [1]   \n",
       "4   {'sel': 2, 'conds': [[3, 0, 'Assen']], 'agg': 0}    [netherlands]   \n",
       "\n",
       "                                           sql_query  \n",
       "0  {'agg_index': 0, 'cond_ops': ['=', '>', '<', '...  \n",
       "1  {'agg_index': 0, 'cond_ops': ['=', '>', '<', '...  \n",
       "2  {'agg_index': 0, 'cond_ops': ['=', '>', '<', '...  \n",
       "3  {'agg_index': 3, 'cond_ops': ['=', '>', '<', '...  \n",
       "4  {'agg_index': 0, 'cond_ops': ['=', '>', '<', '...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f = pd.read_json(\"./data/test_files.json\")\n",
    "train_f = pd.read_json(\"./data/train_files.json\")\n",
    "dev_f = pd.read_json(\"./data/dev_files.json\")\n",
    "print(test_f.columns)\n",
    "test_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caption                                                          R\n",
       "header           [Player, No., Nationality, Position, Years in ...\n",
       "table_id                                             1-10015132-16\n",
       "name                                             table_10015132_16\n",
       "page_id                                                        NaN\n",
       "page_title                         Toronto Raptors all-time roster\n",
       "rows             [[Aleksandar Radojević, 25, Serbia, Center, 19...\n",
       "section_title                                                    R\n",
       "types                         [text, text, text, text, text, text]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tb = spark.read.json(\"./data/test_tables.jsonl\").toPandas().rename(columns={'id':'table_id'})\n",
    "train_tb = spark.read.json(\"./data/train_tables.jsonl\").toPandas().rename(columns={'id':'table_id'})\n",
    "dev_tb = spark.read.json(\"./data/dev_tables.jsonl\").toPandas().rename(columns={'id':'table_id'})\n",
    "test_tb.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_trans(df):\n",
    "    header_list = []\n",
    "    for i, row in df.iterrows():\n",
    "        header_new = list(zip(row['header'], row['types'],row['rows'][0]))\n",
    "        header_list.append(header_new) \n",
    "    df['header_new']=header_list\n",
    "    df = df.drop(columns=['header'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tb= header_trans(test_tb)\n",
    "train_tb= header_trans(train_tb)\n",
    "dev_tb= header_trans(dev_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caption                                                          R\n",
       "table_id                                             1-10015132-16\n",
       "name                                             table_10015132_16\n",
       "page_id                                                        NaN\n",
       "page_title                         Toronto Raptors all-time roster\n",
       "rows             [[Aleksandar Radojević, 25, Serbia, Center, 19...\n",
       "section_title                                                    R\n",
       "types                         [text, text, text, text, text, text]\n",
       "header_new       [(Player, text, Aleksandar Radojević), (No., t...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tb.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test_f,test_tb,on=['table_id']).rename(columns={'question':'context','page_title':'title','header_new':'header'})\n",
    "train = pd.merge(train_f,train_tb,on=['table_id']).rename(columns={'question':'context','page_title':'title','header_new':'header'})\n",
    "dev = pd.merge(dev_f,dev_tb,on=['table_id']).rename(columns={'question':'context','page_title':'title','header_new':'header'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phase            1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "table_id         1-10015132-16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "context          What clu was in toronto 1995-96                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "sql              {'sel': 5, 'conds': [[4, 0, '1995-96']], 'agg': 0}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "answer           [arkansas]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "sql_query        {'agg_index': 0, 'cond_ops': ['=', '>', '<', 'OP'], 'ordered': True, 'syms': ['SELECT', 'WHERE', 'AND', 'COL', 'TABLE', 'CAPTION', 'PAGE', 'SECTION', 'OP', 'COND', 'QUESTION', 'AGG', 'AGGOPS', 'CONDOPS']}                                                                                                                                                                                                                                                                                                                                                            \n",
       "caption          R                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "name             table_10015132_16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "page_id          NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "title            Toronto Raptors all-time roster                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "rows             [[Aleksandar Radojević, 25, Serbia, Center, 1999-2000, Barton CC (KS)], [Shawn Respert, 31, United States, Guard, 1997-98, Michigan State], [Quentin Richardson, N/A, United States, Forward, 2013-present, DePaul], [Alvin Robertson, 7, 21, United States, Guard, 1995-96, Arkansas], [Carlos Rogers, 33, 34, United States, Forward-Center, 1995-98, Tennessee State], [Roy Rogers, 9, United States, Forward, 1998, Alabama], [Jalen Rose, 5, United States, Guard-Forward, 2003-06, Michigan], [Terrence Ross, 31, United States, Guard, 2012-present, Washington]]\n",
       "section_title    R                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "types            [text, text, text, text, text, text]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "header           [(Player, text, Aleksandar Radojević), (No., text, 25), (Nationality, text, Serbia), (Position, text, Center), (Years in Toronto, text, 1999-2000), (School/Club Team, text, Barton CC (KS))]                                                                                                                                                                                                                                                                                                                                                                           \n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_json('./data/test_tabert.json')\n",
    "train.to_json('./data/train_tabert.json')\n",
    "dev.to_json('./data/dev_tabert.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subset of traning sample 100 roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/train_tabert.json')\n",
    "dev = pd.read_json('./data/dev_tabert.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train[:100]\n",
    "dev_subset = dev[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_subset),len(dev_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_json('./data/train_tabert_100.json')\n",
    "dev_subset.to_json('./data/dev_tabert_100.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, minimum_count=1):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "\n",
    "        self.index2word = [None] * 4\n",
    "        self.index2word[SOS_IDX] = SOS_TOKEN\n",
    "        self.index2word[EOS_IDX] = EOS_TOKEN\n",
    "        self.index2word[UNK_IDX] = UNK_TOKEN\n",
    "        self.index2word[PAD_IDX] = PAD_TOKEN\n",
    "\n",
    "        self.word2count[SOS_TOKEN] = 100;\n",
    "        self.word2count[EOS_TOKEN] = 100;\n",
    "        self.word2count[UNK_TOKEN] = 100;\n",
    "        self.word2count[PAD_TOKEN] = 100;\n",
    "\n",
    "        self.word2index[SOS_TOKEN] = SOS_IDX;\n",
    "        self.word2index[EOS_TOKEN] = EOS_IDX;\n",
    "        self.word2index[UNK_TOKEN] = UNK_IDX;\n",
    "        self.word2index[PAD_TOKEN] = PAD_IDX;\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "        self.minimum_count = minimum_count;\n",
    "\n",
    "    def add_ans(self, ans):\n",
    "        for word in ans:\n",
    "            self.addWord(word.lower())\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count.keys():\n",
    "            self.word2count[word] = 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        if self.word2count[word] >= self.minimum_count:\n",
    "            if word not in self.index2word:\n",
    "                word = str(word);\n",
    "                self.word2index[word] = self.n_words\n",
    "                self.index2word.append(word)\n",
    "                self.n_words += 1\n",
    "\n",
    "    def vec2txt(self, list_idx):\n",
    "        word_list = []\n",
    "        if type(list_idx) == list:\n",
    "            for i in list_idx:\n",
    "                if i not in [EOS_IDX, SOS_IDX, PAD_IDX]:\n",
    "                    word_list.append(self.index2word[i])\n",
    "        else:\n",
    "            for i in list_idx:\n",
    "                if i.item() not in [EOS_IDX, SOS_IDX, PAD_IDX]:\n",
    "                    word_list.append(self.index2word[i.item()])\n",
    "        return (' ').join(word_list)\n",
    "\n",
    "    def txt2vec(self, ans):\n",
    "        token_list = ans;\n",
    "        index_list = [self.word2index[token] if token in self.word2index else UNK_IDX for token in token_list]\n",
    "        return torch.from_numpy(np.array(index_list)).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class voc():\n",
    "    def __init__(self, df, voc_location, minimum_count = 1, max_num = 35):\n",
    "        #df here is answers, list of list of tokens\n",
    "        self.df=df\n",
    "        self.minimum_count = minimum_count;\n",
    "        self.max_num = max_num;\n",
    "        self.voc_location = voc_location;\n",
    "        self.main_df, self.target_voc = self.load_or_create_voc()\n",
    "        #main df includes target_tokenized, target_indized, target_len\n",
    "        #target_voc is the Lang class with full vocab and can perform idx to token, token to idx, token to count opertations\n",
    "    def __len__(self):\n",
    "        return len(self.main_df) if self.max_num is None else self.max_num\n",
    "    def __getitem__(self, idx):\n",
    "        return_list = [self.main_df.iloc[idx]['target_indized'], self.main_df.iloc[idx]['target_len'] ]\n",
    "        return return_list\n",
    "    def load_or_create_voc(self):\n",
    "        if not os.path.exists(self.voc_location):\n",
    "            os.makedirs(self.voc_location)\n",
    "        full_file_path = os.path.join(self.voc_location, 'mincnt_maxnum' +\n",
    "                                      str(self.minimum_count) + '_' + \\\n",
    "                                      str(self.max_num)+'.p')\n",
    "        #if the address exits, we will load the dictionary from the full path,\n",
    "        #ow, we will create a new voc dictionary and pickle dump to full path\n",
    "        if os.path.isfile(full_file_path):\n",
    "            print('Load Pre-existing Voc Dictionary')\n",
    "            target_voc = pickle.load(open(full_file_path,'rb'))\n",
    "        else:\n",
    "            print('Create New Voc Dictionary')\n",
    "            target_voc = Lang(minimum_count = self.minimum_count);\n",
    "            for ans in self.df: # load ans into voc\n",
    "                target_voc.add_ans(ans)\n",
    "            pickle.dump(target_voc,open(full_file_path,'wb'))\n",
    "        indices_data = []\n",
    "        for ans in self.df: # ans tokens to idx\n",
    "            index_list = [target_voc.word2index[token] if token in target_voc.word2index else UNK_IDX for token in ans]\n",
    "            if len(index_list)<=self.max_num:\n",
    "                index_list = index_list + [PAD_IDX]*(self.max_num-len(index_list))\n",
    "            else:\n",
    "                index_list = index_list[:self.max_num]\n",
    "            index_list.append(EOS_IDX)\n",
    "            indices_data.append(index_list)\n",
    "        main_df = pd.DataFrame();\n",
    "        main_df['target_tokenized'] = self.df;\n",
    "        main_df['target_indized'] = indices_data;\n",
    "        main_df['target_len'] = main_df['target_tokenized'].apply(lambda x: len(x)+1) #+1 for EOS\n",
    "        main_df =  main_df[main_df['target_len'] >=2] #filter out ans that are empty\n",
    "        return main_df,target_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiDataset():\n",
    "    def __init__(self, path, voc_location, model, minimum_count=1, max_num=35):\n",
    "        # the initalization will end up with four parts: tabs, context, answers and target_voc\n",
    "        self.path = path\n",
    "        self.voc_location = voc_location\n",
    "        self.model = model\n",
    "        self.minimum_count=minimum_count\n",
    "        self.max_num=max_num\n",
    "\n",
    "        self.data = pd.read_json(self.path)\n",
    "        self.data['title'] = self.data['title'].fillna('unknown')\n",
    "        lens = self.data['answer'].apply(lambda x: len(model.tokenizer.tokenize(str(x[0]))))\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "        # print(self.data.shape)\n",
    "\n",
    "        self.tabs = []\n",
    "        self.context = []\n",
    "        self.answers = []\n",
    "\n",
    "        self._build()\n",
    "        self.voc_obj = voc(self.answers, self.voc_location, minimum_count=self.minimum_count, max_num=self.max_num)\n",
    "\n",
    "        self.answers = self.voc_obj.main_df.target_indized.tolist()\n",
    "        self.target_voc=self.voc_obj.target_voc\n",
    "\n",
    "    def _build(self):\n",
    "        for idx in tqdm(range(len(self.data))):\n",
    "            qs = self.data.loc[idx, 'context']\n",
    "            ans = self.data.loc[idx, 'answer']\n",
    "            heads = self.data.loc[idx, 'header']\n",
    "            tit = self.data.loc[idx, 'title']\n",
    "            rs = self.data.loc[idx, 'rows']\n",
    "\n",
    "            col = [Column(z[0], z[1], sample_value=z[2]) for z in heads]\n",
    "            table = Table(\n",
    "                id=tit,\n",
    "                header=col,\n",
    "                data=rs\n",
    "            ).tokenize(self.model.tokenizer)\n",
    "            self.tabs.append(table)\n",
    "\n",
    "            self.context.append(self.model.tokenizer.tokenize(qs))\n",
    "            self.answers.append(self.model.tokenizer.tokenize(str(ans[0])))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.context)\n",
    "    def __getitem__(self, index):\n",
    "        tabi = self.tabs[index]\n",
    "        conti = self.context[index]\n",
    "        ansi = self.answers[index]\n",
    "        return {\"table\": tabi, \"context\": conti, \"answer\": ansi}\n",
    "\n",
    "\n",
    "def get_dataset(path, voc_location, model):\n",
    "    return WikiDataset(path=path, voc_location=voc_location,model=model)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return [batch[i]['table'] for i in range(len(batch))], [batch[i]['context'] for i in range(len(batch))], torch.tensor([batch[i]['answer'] for i in range(len(batch))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TableBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "SEP_IDX = 4\n",
    "PAD_TOKEN = '<pad>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "SEP_TOKEN = '<sep>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56355/56355 [05:21<00:00, 175.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Pre-existing Voc Dictionary\n"
     ]
    }
   ],
   "source": [
    "train = WikiDataset(\"./data/train_tabert.json\",'./voc',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The len of the voc is : 11575\n"
     ]
    }
   ],
   "source": [
    "print('The len of the voc is :',train.target_voc.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabert",
   "language": "python",
   "name": "tabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
